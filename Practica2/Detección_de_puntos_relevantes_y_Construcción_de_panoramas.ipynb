{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visión por Computador - Práctica 2\n",
    "## Detección de puntos relevantes y Construcción de panoramas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Detección de puntos Harris multiescala (MOPS, Brown, Szeliski, Winder, 2004). \n",
    "\n",
    "#### En este apartado se trata de implementar el detector de regiones descrito en el artículo mencionado. En este algoritmo se suponen que todas las imágenes están tomadas en una escala semejante (zoom y distancia iguales) por lo que el objetivo es extraer todas las regiones relevantes que haya a distintas escalas enteras de las imágenes. Por cada región detectada necesitaremos guardar la siguiente información: (las coordenadas x ,y de su centro, su orientación, su escala)). Usar para ello la estructura que resulte más fácil. Presentar los resultados con las imágenes Yosemite.rar.\n",
    "\n",
    "##### a) Escribir una función que extraiga la lista potencial de puntos Harris en una imagen a distintas escalas. Para ello construiremos una pirámide Gaussiana de la imagen con 3 escalas usando $\\sigma = 1$. Sobre cada nivel de la pirámide usar la función OpenCV cornerEigenValsAndVecs para extraer los mapas de auto-valores de la matriz Harris en cada píxel (( fijar los valores de blockSize en el rango [3-13] y ksize en el rango [3-9]) , usar la versión de nivel de gris de las imágenes). Crear una matriz con el valor del criterio selección Harris asociado a cada píxel usando ($k=0.04$). Implementar la fase de supresión de valores non-máximos sobre dicha matriz. Ordenar de mayor-a-menor en cada escala los puntos resultantes de acuerdo a su valor Harris. Seleccionar al menos 1500 puntos de entre los de mayor valor distribuidos entre las distintas escalas (las escalas más bajas tendrán más puntos: 70-20-10). Mostrar el resultado dibujando un círculo sobre la imagen original de radio proporcional a la escala y centro las coordenadas de los puntos.\n",
    "\n",
    "##### b) Extraer los valores (x,y, escala) de los puntos resultantes en el apartado anterior en un vector y refinar su posición espacial a nivel sub-píxel usando la función OpenCV usando cornerSubPix()) con la imagen del nivel de pirámide correspondiente. Actualizar los datos (x,y ,escala) de cada uno de los puntos encontrados. \n",
    "\n",
    "##### c)  Calcular la orientación relevante de cada punto Harris, usando un alisamiento fuerte de las derivadas en x e y de las imágenes, en la escala correspondiente, como propone el paper MOPS de Brown&Szeliski&Winder. (Apartado 2.5) y añadir la información del ángulo al vector de información del punto. Pintar sobre la imagen de círculos anterior un radio en cada círculo indicando la orientación estimada en ese punto."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Apartado a**: para resolver este ejercicio, se han desarrollado varias funciones. Iremos explicándolas poco a poco y viendo su desarrollo.\n",
    "    \n",
    "    Antes de realizar la pirámide Gaussiana, lo primero es ver si la imagen es divisible entre el número de divisiones que vamos a hacer. Esto se hace para que, una vez encontrado un punto relevante en la escala $S_i$, sea más sencillo recuperar la posición original en la que se encontraba el píxel, tan solo multiplicando tantas veces como se haya reducido la imagen para encontrar ese punto. De esto se encarga la función ```prepare_img_to_harris_points``` que recibe como parámetro la imagen de la que detectaremos los puntos.\n",
    "    \n",
    "    Esta función, recibe la imagen, la pasa a escala de grises y añade tantos píxeles como sean necesarios para poder tener una imagen cuyos puntos Harris sean fáciles de recuperar a la escala original."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import cv2\n",
    "import random\n",
    "import numpy as np\n",
    "from functions import *\n",
    "\n",
    "def prepare_img_to_harris_points(img):\n",
    "    # Extraemos las dimensiones de la imagen, para que,\n",
    "    # en caso de que sean de tamaño impar, añadirle las filas\n",
    "    # o columnas que correspondan, para que, al reducir,\n",
    "    # podamos recuperar fácilmente las coordenadas de los puntos\n",
    "    # harris.\n",
    "    alt, anch = img.shape[:2]\n",
    "\n",
    "    gray_img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    aux=[]\n",
    "    # Ensanchamos una fila de la imagen\n",
    "    if alt % 4 != 0 and anch % 4 == 0:\n",
    "        aux = np.ones(shape=(alt + alt % 4, anch), dtype=np.uint8)\n",
    "        insert_img_into_other(img_src=gray_img, img_dest=aux, pixel_left_top_col=0,\n",
    "                              pixel_left_top_row=0, substitute=True)\n",
    "\n",
    "    # Ensanchamos una columna de la imagen\n",
    "    elif alt % 4 == 0 and anch % 4 != 0:\n",
    "        aux = np.ones(shape=(alt, anch + anch % 4), dtype=np.uint8)\n",
    "        insert_img_into_other(img_src=gray_img, img_dest=aux, pixel_left_top_col=0,\n",
    "                              pixel_left_top_row=0, substitute=True)\n",
    "\n",
    "    # Ensanchamos una fila y una columna de la imagen\n",
    "    elif alt % 4 != 0 and anch % 4 != 0:\n",
    "        aux = np.ones(shape=(alt + alt % 4, anch + anch % 4), dtype=np.uint8)\n",
    "        insert_img_into_other(img_src=gray_img, img_dest=aux, pixel_left_top_col=0,\n",
    "                              pixel_left_top_row=0, substitute=True)\n",
    "    # se queda igual que la original\n",
    "    else:\n",
    "        aux = np.copy(gray_img)\n",
    "\n",
    "    return aux\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  Lo siguiente, es generar la pirámide Gaussiana con la función ```generate_gaussian_pyramide``` definida en la práctica anterior, y obtener los puntos en los que su valor de Harris supere un umbral mínimo. En este caso, el umbral se ha definido con un mínimo de $10^{-6}$ para que haya un gran número de puntos para poder obtener suficientes puntos de calidad.\n",
    "  \n",
    "  Para obtener estos puntos, se ha implementado la función ```get_eigenVals_and_eigenVecs```, que recibe como parámetros la pirámide de imágenes de la que se extraerán los puntos, el umbral, el tamaño de bloque (que es el tamaño del vecindario del punto) y el ksize (parámetro para el operador de Sobel). La función tiene un bucle en el que se llama a la función de OpenCV ```cornerEigenValsAndVecs``` que nos devuelve los valores de $\\lambda_1$, $\\lambda_2$, los autovalores y autovectores de ambos. Con ellos calcularemos la traza y el determinante para cada una de las imágenes para obtener el valor de Harris de cada uno de los píxeles de la función. Este valor lo calcularemos siguiendo el criterio histórico de Harris: $$ f = determinant(M) - \\alpha \\cdot trace(M)^2 $$ donde $\\alpha$ es una constante que usaremos con valor 0.04, representada en el código como $k$. Siguiendo esto, obtendremos los valores de cada punto en la matriz, y almacenaremos los índices de los puntos que superan el umbral. Esto lo repetiremos para cada escala:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Criterio histórico de Harris\n",
    "harrisCriterio = lambda det, tr, k=0.04: det - k*(tr**2)\n",
    "\n",
    "# Obtiene los valores de harris y los indices\n",
    "# de los puntos que superan el umbral\n",
    "def get_eigenVals_and_eigenVecs(pyramide, thresdhold, blockS, kSize):\n",
    "    eingen_vals_and_vecs = []\n",
    "    strong_values = []\n",
    "\n",
    "    for im in pyramide:\n",
    "        # Obtenemos la matriz de con los autovalores de la matriz\n",
    "        # y los respectivos autovectores para cada uno de los autovalores\n",
    "        result = cv2.split(cv2.cornerEigenValsAndVecs(src=im.astype(np.uint8),\n",
    "                                                      blockSize=blockS, ksize=kSize))\n",
    "        # Calculamos el determinante como el producto de los autovalores\n",
    "        det = cv2.mulSpectrums(result[0], result[1], flags=cv2.DFT_ROWS)\n",
    "        # Calculamos la traza como la suma de los autovalores\n",
    "        trace = result[0] + result[1]\n",
    "        # Realizamos la función de valoración de Harris\n",
    "        eingen_vals_and_vecs.append(harrisCriterio(det, trace))\n",
    "        # Y obtenemos los índices de los píxeles que sobrepasan el umbral mínimo\n",
    "        strong_values.append(np.where(eingen_vals_and_vecs[-1] > thresdhold))\n",
    "\n",
    "    return eingen_vals_and_vecs, strong_values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tras esto, pasaremos a obtener los puntos que conforman un máximo local dentro de su entorno, en los puntos obtenidos en la función anterior. Para ello, definiremos una serie de funciones que se encargarán de hacer este trabajo. Estas funciones son:\n",
    "- ```local_maximum```: recibe como parámetro un entorno o vecindario de un punto perteneciente a la matriz con los valores de Harris obtenidos en la función anterior, y comprueba si el valor del centro, es el máximo local.\n",
    "- ```get_local_maximun```: se encarga de obtener todos los máximos locales de los puntos extraídos, para obtener los puntos de mayor calidad de los que han sobrepasado el umbral. Tras esto, devolvemos las coordenadas de los puntos máximos, junto con su valor de Harris."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Esta función comprueba si el centro del entorno es\n",
    "# un máximo local o no\n",
    "def local_maximun(environment):\n",
    "    floor = math.floor\n",
    "    height, width = environment.shape[:2]\n",
    "    center = environment[floor(width/2),floor(height/2)]\n",
    "    return center == np.max(environment)\n",
    "\n",
    "\n",
    "def get_local_maximun(imgs, index_mask, mask_size):\n",
    "    # obtenemos los índices de los puntos que han sobrepasado\n",
    "    # el umbral mínimo\n",
    "    escala = 1\n",
    "    img = 0\n",
    "    xy_bests_points = []\n",
    "    harrisV_bests_points = []\n",
    "    for i in index_mask:\n",
    "        # Arrays para almacenar las coordenadas en X y en Y\n",
    "        coord_x = []\n",
    "        coord_y = []\n",
    "        rows = i[0]\n",
    "        cols = i[1]\n",
    "        # Extendemos la imagen para poder captar fácilmente\n",
    "        # los máximos locales de los bordes\n",
    "        imgaux = extend_image_n_pixels(img_src=imgs[img],\n",
    "                                       border_type=4,\n",
    "                                       n_pixels=mask_size)\n",
    "        # Array para almacenar los máximos locales almacenados\n",
    "        maxHs = []\n",
    "        for k in range(len(rows)):\n",
    "            # Obtenemos las cuatro esquinas de la región a analizar\n",
    "            left = rows[k]\n",
    "            right = (rows[k]+mask_size)\n",
    "            top = cols[k]\n",
    "            down = (cols[k] + mask_size)\n",
    "            # Y comprobamos si la región contiene en su centro un máximo local\n",
    "            if local_maximun(imgaux[left:right, top:down]):\n",
    "                # si lo es, almacenamos su posición y su valor harris\n",
    "                coord_x.append(rows[k])\n",
    "                coord_y.append(cols[k])\n",
    "                maxHs.append(imgs[img][rows[k],cols[k]])\n",
    "\n",
    "        # Insertamos los puntos máximos y su valor en la lista\n",
    "        xy_bests_points.append(np.array([np.array(coord_x), np.array(coord_y)]))\n",
    "        # xy_bests_points.append(maxls_xy)\n",
    "        harrisV_bests_points.append(maxHs)\n",
    "        img += 1\n",
    "        escala *= 2\n",
    "\n",
    "    return xy_bests_points, harrisV_bests_points\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una vez encontrados los máximos locales, pasamos a encontrar y seleccionar los mejores puntos de cada escala. En la escala más baja (la original) encontraremos el mayor número de puntos, y cada vez que subamos un nivel en la pirámide, seleccionaremos menos, escogiendo el 70%, el 20% y el 10% en cada uno de los niveles respectivamente.\n",
    "\n",
    "De esto se encarga la función ```get_best_points```, que en cada nivel, ordena los puntos máximos de mayor a menor según su valor de Harris, y selecciona el porcentaje de puntos que queremos de cada nivel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_best_points(img_points, xy_points, harrisV, n_points):\n",
    "    # Pasamos a poner a 1 los puntos con máximos locales\n",
    "    it = 0\n",
    "    floor = math.floor\n",
    "    # Esto representa el porcentaje de puntos que tomaremos de cada escala\n",
    "    # tomando del primer nivel el 70%, del segundo el 20% y del último el 10%\n",
    "    percentages = [.7, .2, .1]\n",
    "    escala = 1\n",
    "    selected_points = []\n",
    "    # Empezamos a recorrer los puntos que hemos extraído como máximos locales\n",
    "    for points in harrisV:\n",
    "        # ordenamos los puntos. Como argsort los da ordenados\n",
    "        # de menor a mayor, invertimos el vector para obtenerlos\n",
    "        # de mayor a menor.\n",
    "        index = np.argsort(points)[::-1]\n",
    "        # tomamos las coordenadas del % de puntos mejores\n",
    "        coord_xy = [xy_points[it][0][index[0:floor(n_points * percentages[it])]],\n",
    "                    xy_points[it][1][index[0:floor(n_points * percentages[it])]]]\n",
    "\n",
    "        # Almacenamos los mejores puntos de cada escala\n",
    "        # ya ordenados, y sin\n",
    "        selected_points.append(np.array(coord_xy).T)\n",
    "\n",
    "        # Almacenamos los puntos en una lista para poder\n",
    "        # dibujar los círculos\n",
    "        coordinates_for_circles = [xy_points[it][1][index[0:floor(n_points * percentages[it])]] * escala,\n",
    "                                        xy_points[it][0][index[0:floor(n_points * percentages[it])]] * escala,]\n",
    "        # coordinates_for_circles.append(coord_xy*escala)\n",
    "        # y los ponemos a 1\n",
    "        img_points[coordinates_for_circles[::-1]] = 255\n",
    "        it += 1\n",
    "        escala *= 2\n",
    "\n",
    "    show_img(img_points, \"Primeros puntos seleccionados\")\n",
    "\n",
    "    return selected_points"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **Apartado b**: una vez que tenemos los mejores puntos de cada nivel, pasamos a refinar estos puntos a nivel de subpíxel. Para ello, implementaremos la función ```refine_points```, que recibe como parámetros la pirámide de imágenes, y los puntos seleccionados. \n",
    "    Para cada punto de cada nivel, se refina a nivel de subpíxel llamando a la función de *OpenCV* ```cornerSubPix```, almacenandolo en una lista multinivel los puntos que hemos refinado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def refine_points(pyramide, selected_points):\n",
    "    refined_points = []\n",
    "    it = 0\n",
    "\n",
    "    for img in pyramide:\n",
    "        float_esquinas = np.array(selected_points[it], dtype=np.float32).copy()\n",
    "        cv2.cornerSubPix(image=img.astype(np.float32), corners=float_esquinas,\n",
    "                         winSize=(5, 5), zeroZone=(-1, -1),\n",
    "                         criteria=(cv2.TERM_CRITERIA_MAX_ITER | cv2.TERM_CRITERIA_COUNT, 10, 0.01))\n",
    "        it += 1\n",
    "        refined_points.append(float_esquinas)\n",
    "\n",
    "    return refined_points"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "* **Apartado c**: una vez refinados los píxeles a nivel de subpíxel, pasamos a obtener la dirección estimada del gradiente en ese punto. Para ello, derivamos la imagen en $\\mathcal{X}$ y en $\\mathcal{Y}$. Una vez derivada la imagen, para obtener el ángulo, realizamos lo siguiente: $$\\arctan\\left(\\frac{dy}{dx}\\right)$$\n",
    "\n",
    "    Una vez hecho esto, el ángulo tendremos que convertirlo de radianes a grados para trabajar con OpenCV, multiplicando por 180 y dividiendo por $\\pi$. Tras esto almacenamos los puntos en una lista."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def detect_angles(pyramide, refined_points):\n",
    "    # inicializamos la lista con los ángulos\n",
    "    angles = []\n",
    "    # y recorremos las tres escalas\n",
    "    for scale in range(3):\n",
    "        dx_img, dy_img = get_derivates_of(img=pyramide[scale], sigma=4.5)\n",
    "        # Obtenemos los indices para poder\n",
    "        indices = np.array(refined_points[scale].T, dtype=int)\n",
    "        # Calculamos los ángulos de forma vectorizada, donde\n",
    "        # el ángulo es:\n",
    "        #           ang = atan( dy/dx )\n",
    "        angles.append((np.arctan2(dy_img[indices[0], indices[1]],\n",
    "                                  dx_img[indices[0], indices[1]]))*180/np.pi)\n",
    "\n",
    "    # Devolvemos los ángulos\n",
    "    return angles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tras esto, solo nos queda presentar si se desea el resultado obtenido, y devolverlo. Para presentarlo, se ha definido la siguiente función, ```show_result```, que recibe como parámetros la imagen original, los puntos refinados y el ángulo. Para cada uno de las escalas, se usa un radio distinto, donde para los niveles más altos de la pirámide, se usan radios más grandes. A su vez, cambiará el color según las escalas, siendo de color azul la escala original, verde la intermedia y roja la última escala."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def show_result(img, refined_points, angles, thick):\n",
    "    aux2 = np.copy(img)\n",
    "    floor = math.floor\n",
    "    sin = np.sin\n",
    "    cos = np.cos\n",
    "    radio = [5, 10, 20]\n",
    "    colors = [(175, 0, 0), (0, 175, 0), (0, 0, 175)]\n",
    "    size = 1\n",
    "    for scale in range(3):\n",
    "        for i in random.sample(range(len(refined_points[scale])), 100):\n",
    "        # for i in range(len(refined_points[scale])):\n",
    "            punto = refined_points[scale][i].astype(np.int) * size\n",
    "            angle = angles[scale][i]\n",
    "            cv2.circle(img=aux2, center=(punto[1], punto[0]),\n",
    "                       radius=radio[scale], color=colors[scale],\n",
    "                       thickness=thick)\n",
    "            cv2.arrowedLine(img=aux2, pt1=(punto[1], punto[0]),\n",
    "                            pt2=(punto[1] + floor(sin(angle) * radio[scale]),\n",
    "                                 punto[0] + floor(cos(angle) * radio[scale])),\n",
    "                            color=colors[scale],thickness=thick)\n",
    "        size *= 2\n",
    "\n",
    "    show_img(aux2, 'Puntos y ángulos')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con todo esto, podemos generar la función ```extract_harris_points``` que recibe como parámetros la imagen de entrada, blockS, kSize, el umbral, el número de puntos que queremos extraer y parámetros para si queremos mostrar los resultados o no, y el grosor de la línea que forma la circunferencia que indica la posición y escala a la que se ha encontrado el punto, y el radio que indica su dirección aproximada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def extract_harris_points(img, blockS, kSize, thresdhold, n_points = 1500,\n",
    "                          show_best_points = True,\n",
    "                          thick = 1):\n",
    "    #######################################\n",
    "    # Apartado a: extrare lista potencial\n",
    "    # de puntos Harris\n",
    "    #######################################\n",
    "    alt, anch = img.shape[:2]\n",
    "    aux = prepare_img_to_harris_points(img)\n",
    "    # obtenemos la pirámide gaussiana\n",
    "    pyramide = generate_gaussian_pyramide(img_src=aux, subsample_factor=2, n_levels=3)\n",
    "\n",
    "    # Obtenemos los autovalores y autovectores, junto\n",
    "    # con los puntos que superan el umbral\n",
    "    eingen_vals_and_vecs, strong_values = \\\n",
    "        get_eigenVals_and_eigenVecs(pyramide, thresdhold, blockS, kSize)\n",
    "\n",
    "    # pasamos a eliminar los no máximos\n",
    "    xy_points, harrisV = get_local_maximun(imgs=eingen_vals_and_vecs,\n",
    "                                           index_mask=strong_values,\n",
    "                                           mask_size=3)\n",
    "    # inicializamos una imagen binaria (0,255) para\n",
    "    # representar los máximos locales de la imagen\n",
    "    img_points = np.zeros(shape=img.shape,dtype=np.uint8)\n",
    "    # Obtenemos los mejores puntos para cada uno de\n",
    "    # los niveles\n",
    "\n",
    "    selected_points = get_best_points(img_points, xy_points, harrisV, n_points)\n",
    "\n",
    "    #######################################\n",
    "    # Apartado b, refinar las coordenadas\n",
    "    #######################################\n",
    "    refined_points = refine_points(pyramide, selected_points)\n",
    "\n",
    "    ####################################\n",
    "    # Apartado c, detectar orientacion\n",
    "    ####################################\n",
    "    # Eliminamos aquellos puntos que puedan haberse excedido del\n",
    "    # tamaño de la imagen\n",
    "    refined_points[0] = np.delete(refined_points[0],\n",
    "                                  np.where(refined_points[0][:, 0] > alt), 0)\n",
    "    refined_points[0] = np.delete(refined_points[0],\n",
    "                                  np.where(refined_points[0][0, :] > anch), 0)\n",
    "\n",
    "    # Obtenemos los ángulos de los gradientes\n",
    "    angles =  detect_angles(pyramide, refined_points)\n",
    "    # y mostramos el resultado si procede\n",
    "    if show_best_points:\n",
    "        show_result(img, refined_points, angles, thick)\n",
    "\n",
    "    return refined_points, angles"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
